#!/usr/bin/env python2
######################################################################
#
# File: b2
#
# Copyright 2015 Backblaze Inc. All Rights Reserved.
#
# License https://www.backblaze.com/using_b2_code.html
#
######################################################################

"""
This is a B2 command-line tool.  See the USAGE message for details.
"""

import datetime
import getpass
import hashlib
import json
import os.path
import sys
import urllib
import urllib2
import base64

VERSION = '0.3.5'

USAGE = """This program provides command-line access to the B2 service.

Usages:

    b2 authorize_account [--dev | --staging | --production] [accountId] [applicationKey]

        Prompts for Backblaze accountID and applicationKey (unless they are given
        on the command line).

        The account ID is a 12-digit hex number that you can get from
        your account page on backblaze.com.

        The application key is a 40-digit hex number that you can get from
        your account page on backblaze.com.

        Stores an account auth token in ~/.b2_account_info

    b2 clear_account

        Erases everything in ~/.b2_account_info

    b2 create_bucket <bucketName> <bucketType>

        Creates a new bucket.  Prints the ID of the bucket created.

    b2 delete_bucket <bucketName>

        Deletes the bucket with the given name.

    b2 delete_file_version <fileName> <fileId>

        Permanently and irrevocably deletes one version of a file.

    b2 download_file_by_id <fileId> <localFileName>

        Downloads the given file, and stores it in the given local file.

    b2 download_file_by_name <bucketName> <fileName> <localFileName>

        Downloads the given file, and stores it in the given local file.

    b2 get_file_info <fileId>

        Prints all of the information about the file, but not its contents.

    b2 hide_file <bucketName> <fileName>

        Uploads a new, hidden, version of the given file.

    b2 list_buckets

        Lists all of the buckets in the current account.

    b2 list_file_names <bucketName> [<startingName>] [<numberToShow>]

        Lists the names of the files in a bucket, starting at the
        given point.

    b2 list_file_versions <bucketName> [<startingName>] [<startingFileId>] [<numberToShow>]

        Lists the names of the files in a bucket, starting at the
        given point.

    b2 ls [--long] [--versions] <bucketName> [<folderName>]

        Using the file naming convention that "/" separates folder
        names from their contents, returns a list of the files
        and folders in a given folder.  If no folder name is given,
        lists all files at the top level.

        The --long option produces very wide multi-column output
        showing the upload date/time, file size, file id, whether it
        is an uploaded file or the hiding of a file, and the file
        name.  Folders don't really exist in B2, so folders are
        shown with "-" in each of the fields other than the name.

        The --version option shows all of versions of each file, not
        just the most recent.

    b2 make_url <fileId>

        Prints an URL that can be used to download the given file, if
        it is public.

    b2 update_bucket <bucketName> <bucketType>

        Updates the bucketType of an existing bucket.  Prints the ID
        of the bucket updated.

    b2 upload_file [--contentType <contentType>] [--info <key>=<value>]* <bucketName> <localFilePath> <b2FileName>

        Uploads one file to the given bucket.  Uploads the contents
        of the local file, and assigns the given name to the B2 file.

        Content type is optional.  If not set, it will be set based on the
        file extension.

        Each fileInfo is of the form "a=b".

    b2 version

        Echos the version number of this program.
"""


def message_and_exit(message):
    """Prints a message, and exits with error status.
    """
    print >>sys.stderr, message
    sys.exit(1)


def usage_and_exit():
    """Prints a usage message, and exits with an error status.
    """
    message_and_exit(USAGE)


def decode_sys_argv():
    """
    Returns the command-line arguments as unicode strings, decoding
    whatever format they are in.

    https://stackoverflow.com/questions/846850/read-unicode-characters-from-command-line-arguments-in-python-2-x-on-windows
    """
    encoding = sys.getfilesystemencoding()
    return [arg.decode(encoding) for arg in sys.argv]


class StoredAccountInfo(object):

    """Manages the file that holds the account ID and stored auth tokens.

    When an instance of this class is created, it reads the account
    info file in the home directory of the user, and remembers the info.

    When any changes are made, they are written out to the file.
    """

    ACCOUNT_AUTH_TOKEN = 'account_auth_token'
    ACCOUNT_ID = 'account_id'
    API_URL = 'api_url'
    BUCKET_NAMES_TO_IDS = 'bucket_names_to_ids'
    BUCKET_UPLOAD_DATA = 'bucket_upload_data'
    BUCKET_UPLOAD_URL = 'bucket_upload_url'
    BUCKET_UPLOAD_AUTH_TOKEN = 'bucket_upload_auth_token'
    DOWNLOAD_URL = 'download_url'

    def __init__(self):
        self.filename = os.path.expanduser('~/.b2_account_info')
        self.data = self._try_to_read_file()
        if self.BUCKET_UPLOAD_DATA not in self.data:
            self.data[self.BUCKET_UPLOAD_DATA] = {}
        if self.BUCKET_NAMES_TO_IDS not in self.data:
            self.data[self.BUCKET_NAMES_TO_IDS] = {}

    def clear(self):
        """Removes all stored information.
        """
        self.data = {}
        self._write_file()


    def _try_to_read_file(self):
        try:
            with open(self.filename, 'rb') as f:
                return json.loads(f.read())
        except Exception as e:
            return {}

    def get_account_id(self):
        return self._get_account_info_or_exit(self.ACCOUNT_ID)

    def get_account_auth_token(self):
        return self._get_account_info_or_exit(self.ACCOUNT_AUTH_TOKEN)

    def get_api_url(self):
        return self._get_account_info_or_exit(self.API_URL)

    def get_download_url(self):
        return self._get_account_info_or_exit(self.DOWNLOAD_URL)

    def _get_account_info_or_exit(self, key):
        """Returns the named field from the account data, or errors and exits.
        """
        result = self.data.get(key)
        if result is None:
            message_and_exit('ERROR: No account.  Use: b2 authorize_account')
        return result

    def set_account_id_and_auth_token(self, account_id, auth_token, api_url, download_url):
        self.data[self.ACCOUNT_ID] = account_id
        self.data[self.ACCOUNT_AUTH_TOKEN] = auth_token
        self.data[self.API_URL] = api_url
        self.data[self.DOWNLOAD_URL] = download_url
        self._write_file()

    def set_bucket_upload_data(self, bucket_id, upload_url, upload_auth_token):
        self.data[self.BUCKET_UPLOAD_DATA][bucket_id] = {self.BUCKET_UPLOAD_URL : upload_url, self.BUCKET_UPLOAD_AUTH_TOKEN : upload_auth_token}
        self._write_file()

    def get_bucket_upload_data(self, bucket_id):
        return self.data[self.BUCKET_UPLOAD_DATA].get(bucket_id)

    def save_bucket_name(self, bucket_name, bucket_id):
        names_to_ids = self.data[self.BUCKET_NAMES_TO_IDS]
        if bucket_name not in names_to_ids:
            names_to_ids[bucket_name] = bucket_id
            self._write_file()

    def refresh_entire_bucket_name_cache(self, name_id_iterable):
        names_to_ids = self.data[self.BUCKET_NAMES_TO_IDS]
        new_cache = dict(name_id_iterable)
        if names_to_ids != new_cache:
            self.data[self.BUCKET_NAMES_TO_IDS] = new_cache
            self._write_file()

    def remove_bucket_name(self, bucket_name):
        names_to_ids = self.data[self.BUCKET_NAMES_TO_IDS]
        if bucket_name in names_to_ids:
            del names_to_ids[bucket_name]
        self._write_file()

    def get_bucket_id_or_none_from_bucket_name(self, bucket_name):
        names_to_ids = self.data[self.BUCKET_NAMES_TO_IDS]
        return names_to_ids.get(bucket_name)

    def _write_file(self):
#       with open(self.filename, 'wb') as f:
        with os.fdopen(os.open(self.filename, os.O_WRONLY | os.O_CREAT, 0600), 'wb') as f:
            f.write(json.dumps(self.data, indent=4, sort_keys=True))
            f.write('\n')


class OpenUrl(object):
    """
    Context manager that handles an open urllib2.Request, and provides
    the file-like object that is the response.
    """

    def __init__(self, url, data, headers):
        self.url = url
        self.data = data
        self.headers = headers
        self.file = None

    def __enter__(self):
        try:
            request = urllib2.Request(self.url, self.data, self.headers)
            self.file = urllib2.urlopen(request)
            return self.file
        except urllib2.HTTPError as e:
            print 'Error returned from server:'
            print
            print 'URL:', self.url
            print 'Params:', self.data
            print 'Headers:', self.headers
            print
            print e.read()
            sys.exit(1)

    def __exit__(self, exception_type, exception, traceback):
        if self.file is not None:
            self.file.close()


def post_json(url, params, auth_token=None):
    """Coverts params to JSON and posts them to the given URL.

    Returns the resulting JSON, decoded into a dict.
    """
    data = json.dumps(params)
    headers = {}
    if auth_token is not None:
        headers['Authorization'] = auth_token
    with OpenUrl(url, data, headers) as f:
        json_text = f.read()
        return json.loads(json_text)


def post_file(url, headers, file_path):
    """Posts the contents of the file to the URL.
    """
    with open(file_path, 'rb') as data_file:
        if 'Content-Length' not in headers:
            headers['Content-Length'] = str(os.path.getsize(file_path))
        with OpenUrl(url, data_file, headers) as response_file:
            json_text = response_file.read()
            return json.loads(json_text)


def clear_account(args):
    if len(args) != 0:
        usage_and_exit()
    info = StoredAccountInfo()
    info.clear()


def url_for_api(info, api_name):
    if api_name in ['b2_download_file_by_id']:
        base = info.get_download_url()
    else:
        base = info.get_api_url()
    return base + '/b2api/v1/' + api_name


def b2_url_encode(s):
    """URL-encodes a unicode string to be sent to B2 in an HTTP header.
    """
    return urllib.quote(s.encode('utf-8'))


def b2_url_decode(s):
    """Decodes a Unicode string returned from B2 in an HTTP header.

    Returns a Python unicode string.
    """
    # Use str() to make sure that the input to unquote is a str, not
    # unicode, which ensures that the result is a str, which allows
    # the decoding to work properly.
    return urllib.unquote_plus(str(s)).decode('utf-8')


def authorize_account(args):

    auth_urls = {'--production':'https://api.backblaze.com','--dev':'http://api.test.blaze:8180','--staging':'https://api.backblaze.net'}

    option = '--production'
    url = auth_urls[option]
    while 0 < len(args) and args[0][0] == '-':
        option = args[0]
        args = args[1:]
        if option in auth_urls:
            url = auth_urls[option]
            break
        else:
            print 'ERROR: unknown option', option
            usage_and_exit()

    print 'Using %s' % url

    if 2 < len(args):
        usage_and_exit()
    if 0 < len(args):
        accountId = args[0]
    else:
        accountId = raw_input('Backblaze account ID: ')

    if 1 < len(args):
        applicationKey = args[1]
    else:
        applicationKey = getpass.getpass('Backblaze application key: ')

    url += '/b2api/v1/b2_authorize_account'

    auth = 'Basic '+ base64.b64encode('%s:%s' % (accountId, applicationKey))
    response = post_json(url, {}, auth)

    info = StoredAccountInfo()
    info.clear()
    info.set_account_id_and_auth_token(
        response['accountId'],
        response['authorizationToken'],
        response['apiUrl'],
        response['downloadUrl']
        )


def call_list_buckets(info):
    """Calls b2_list_buckets and returns the JSON for *all* buckets.
    """
    account_id = info.get_account_id()
    auth_token = info.get_account_auth_token()

    url = url_for_api(info, 'b2_list_buckets')
    params = {'accountId': account_id}
    response = post_json(url, params, auth_token)
    info.refresh_entire_bucket_name_cache(
        (bucket['bucketName'], bucket['bucketId'])
        for bucket in response['buckets']
        )
    return response


def get_bucket_id_from_bucket_name(info, bucket_name):
    """
    Returns the bucket_id for the given bucket_name.

    If we don't already know it from the info, try fetching it from
    the B2 service.
    """
    # If we can get it from the stored info, do that.
    result = info.get_bucket_id_or_none_from_bucket_name(bucket_name)
    if result is not None:
        return result

    # Call list_buckets to get the IDs of *all* buckets for this
    # account.
    response = call_list_buckets(info)

    result = info.get_bucket_id_or_none_from_bucket_name(bucket_name)
    if result is None:
        print 'No such bucket:', bucket_name
        sys.exit(1)
    return result


def list_buckets(args):
    if len(args) != 0:
        usage_and_exit()

    info = StoredAccountInfo()
    response = call_list_buckets(info)

    for bucket in response['buckets']:
        bucket_name = bucket['bucketName']
        bucket_id = bucket['bucketId']
        bucket_type = bucket['bucketType']
        print '%s  %-10s  %s' % (bucket_id, bucket_type, bucket_name)


def create_bucket(args):
    if len(args) != 2:
        usage_and_exit()

    info = StoredAccountInfo()
    auth_token = info.get_account_auth_token()

    bucket_name = args[0]
    bucket_type = args[1]

    url = url_for_api(info, 'b2_create_bucket')
    params = {
        'accountId' : info.get_account_id(),
        'bucketName' : bucket_name,
        'bucketType' : bucket_type
        }
    response = post_json(url, params, auth_token)
    print response['bucketId']

    info.save_bucket_name(bucket_name, response['bucketId'])


def delete_bucket(args):
    if len(args) != 1:
        usage_and_exit()

    info = StoredAccountInfo()
    auth_token = info.get_account_auth_token()

    bucket_name = args[0]
    bucket_id = get_bucket_id_from_bucket_name(info, bucket_name)

    url = url_for_api(info, 'b2_delete_bucket')
    params = {
        'accountId' : info.get_account_id(),
        'bucketId' : bucket_id
        }
    response = post_json(url, params, auth_token)

    print json.dumps(response, indent=4, sort_keys=True)


def update_bucket(args):
    if len(args) != 2:
        usage_and_exit()

    info = StoredAccountInfo()
    account_id = info.get_account_id()
    bucket_name = args[0]
    bucket_type = args[1]

    info = StoredAccountInfo()
    bucket_id = get_bucket_id_from_bucket_name(info, bucket_name)
    auth_token = info.get_account_auth_token()

    url = url_for_api(info, 'b2_update_bucket')
    params = {
        'accountId' : account_id,
        'bucketId' : bucket_id,
        'bucketType' : bucket_type
    }
    response = post_json(url, params, auth_token)

    print json.dumps(response, indent=4, sort_keys=True)

def list_file_names(args):

    if len(args) < 1 or 3 < len(args):
        usage_and_exit()

    bucket_name = args[0]
    if 2 <= len(args):
        firstFileName = args[1]
    else:
        firstFileName = None
    if 3 <= len(args):
        count = int(args[2])
    else:
        count = 100

    info = StoredAccountInfo()
    bucket_id = get_bucket_id_from_bucket_name(info, bucket_name)
    auth_token = info.get_account_auth_token()

    url = url_for_api(info, 'b2_list_file_names')
    params = {
        'bucketId' : bucket_id,
        'startFileName' : firstFileName,
        'maxFileCount' : count
    }
    response = post_json(url, params, auth_token)

    print json.dumps(response, indent=2, sort_keys=True)

def list_file_versions(args):

    if len(args) < 1 or 4 < len(args):
        usage_and_exit()

    bucket_name = args[0]
    if 2 <= len(args):
        firstFileName = args[1]
    else:
        firstFileName = None
    if 3 <= len(args):
        firstFileId = args[2]
    else:
        firstFileId = None
    if 4 <= len(args):
        count = int(args[3])
    else:
        count = 100

    info = StoredAccountInfo()
    bucket_id = get_bucket_id_from_bucket_name(info, bucket_name)
    auth_token = info.get_account_auth_token()

    url = url_for_api(info, 'b2_list_file_versions')
    params = {
        'bucketId' : bucket_id,
        'startFileName' : firstFileName,
        'startFileId' : firstFileId,
        'maxFileCount' : count
    }
    response = post_json(url, params, auth_token)

    print json.dumps(response, indent=2, sort_keys=True)

def ensure_upload_data(bucket_id, info):
    """
    Makes sure that we have an upload URL and auth token for the given bucket and
    returns it.
    """
    upload_data = info.get_bucket_upload_data(bucket_id)
    if upload_data is None:
        print 'Getting upload URL...'
        auth_token = info.get_account_auth_token()
        url = url_for_api(info, 'b2_get_upload_url')
        params = { 'bucketId' : bucket_id }
        response = post_json(url, params, auth_token)
        upload_url = response['uploadUrl']
        upload_auth_token = response['authorizationToken']
        info.set_bucket_upload_data(bucket_id, upload_url, upload_auth_token)
        upload_data = info.get_bucket_upload_data(bucket_id)
    return upload_data

def get_file_info(args):
    if len(args) != 1:
        usage_and_exit()
    file_id = args[0]
    bucket_id = file_id[3:27]

    info = StoredAccountInfo()
    auth_token = info.get_account_auth_token()

    url = url_for_api(info, 'b2_get_file_info')
    params = { 'fileId' : file_id }
    response = post_json(url, params, auth_token)

    print json.dumps(response, indent=2, sort_keys=True)

def delete_file_version(args):
    if len(args) != 2:
        usage_and_exit()
    file_name = args[0]
    file_id = args[1]

    info = StoredAccountInfo()
    auth_token = info.get_account_auth_token()

    url = url_for_api(info, 'b2_delete_file_version')
    params = { 'fileName' : file_name, 'fileId' : file_id }
    response = post_json(url, params, auth_token)

    print json.dumps(response, indent=2, sort_keys=True)

def hide_file(args):
    if len(args) != 2:
        usage_and_exit()
    bucket_name = args[0]
    file_name = args[1]

    info = StoredAccountInfo()
    bucket_id = get_bucket_id_from_bucket_name(info, bucket_name)
    auth_token = info.get_account_auth_token()

    url = url_for_api(info, 'b2_hide_file')
    params = {
        'bucketId' : bucket_id,
        'fileName' : file_name
    }
    response = post_json(url, params, auth_token)

    print json.dumps(response, indent=2, sort_keys=True)


def hex_sha1_of_file(path):
    with open(path, 'rb') as f:
        block_size = 1024 * 1024
        digest = hashlib.sha1()
        while True:
            data = f.read(block_size)
            if len(data) == 0:
                break
            digest.update(data)
        return digest.hexdigest()


def parse_file_info(item, file_infos):
    parts = item.split('=')
    if len(parts) != 2:
        print >>sys.stdout, 'ERROR: bad file info:', item
        sys.exit(1)
    file_infos[parts[0]] = parts[1]


def upload_file(args):

    content_type = 'b2/x-auto'
    file_infos = {}
    while 0 < len(args) and args[0][0] == '-':
        option = args[0]
        if option == '--contentType':
            if len(args) < 2:
                usage_and_exit()
            content_type = args[1]
            args = args[2:]
        elif option == '--info':
            if len(args) < 2:
                usage_and_exit()
            parse_file_info(args[1], file_infos)
            args = args[2:]
        else:
            usage_and_exit()

    if len(args) != 3:
        usage_and_exit()
    bucket_name = args[0]
    local_file = args[1]
    b2_file = args[2]

    info = StoredAccountInfo()
    bucket_id = get_bucket_id_from_bucket_name(info, bucket_name)
    bucket_upload_data = ensure_upload_data(bucket_id, info)

    headers = {
        'Authorization': bucket_upload_data[StoredAccountInfo.BUCKET_UPLOAD_AUTH_TOKEN],
        'X-Bz-File-Name': b2_url_encode(b2_file),
        'Content-Type': content_type,
        'X-Bz-Content-Sha1': hex_sha1_of_file(local_file)
        }
    for (k, v) in file_infos.iteritems():
        headers['X-Bz-Info-' + k] = b2_url_encode(v)
    url = bucket_upload_data[StoredAccountInfo.BUCKET_UPLOAD_URL]
    response = post_file(url, headers, local_file)
    print json.dumps(response, indent=4, sort_keys=True)
    if 'fileId' in response:
        print "URL by file name: " + info.get_download_url() + "/file/" + bucket_name + "/" +  b2_file
        print "URL by fileId: " + info.get_download_url() + "/b2api/v1/b2_download_file_by_id?fileId=" + response['fileId']


def download_file_from_url(url, request_body, encoded_headers, local_file_name):
    with OpenUrl(url, request_body, encoded_headers) as response:
        info = response.info()
        file_size = int(info['content-length'])
        file_sha1 = info['x-bz-content-sha1']
        print 'File name:   ', info['x-bz-file-name']
        print 'File size:   ', file_size
        print 'Content type:', info['content-type']
        print 'Content sha1:', file_sha1
        for name in info:
            if name.startswith('x-bz-info-'):
                print 'INFO', name[10:] + ':', info[name]
        block_size = 4096
        digest = hashlib.sha1()
        bytes_read = 0
        with open(local_file_name, 'wb') as f:
            while True:
                data = response.read(block_size)
                if len(data) == 0:
                    break
                f.write(data)
                digest.update(data)
                bytes_read += len(data)
        if bytes_read != int(info['content-length']):
            print 'ERROR: only %d of %d bytes read' % (bytes_read, file_size)
        if digest.hexdigest() != file_sha1:
            print 'ERROR: sha1 checksum mismatch -- bad data'
        print 'checksum matches'


def download_file_by_id(args):
    if len(args) != 2:
        usage_and_exit()

    file_id = args[0]
    local_file_name = args[1]

    info = StoredAccountInfo()
    auth_token = info.get_account_auth_token()

    url = url_for_api(info, 'b2_download_file_by_id')
    headers = { 'Authorization' : auth_token }
    params = { 'fileId' : file_id }

    request_body = json.dumps(params)

    download_file_from_url(url, request_body, headers, local_file_name)


def download_file_by_name(args):
    if len(args) != 3:
        usage_and_exit()

    bucket_name = args[0]
    file_name = args[1]
    local_file_name = args[2]

    info = StoredAccountInfo()
    auth_token = info.get_account_auth_token()

    url = info.get_download_url() + '/file/' + b2_url_encode(bucket_name) + '/' + b2_url_encode(file_name)
    headers = { 'Authorization' : auth_token }

    download_file_from_url(url, None, headers, local_file_name)


def make_url(args):
    if len(args) != 1:
        usage_and_exit()

    file_id = args[0]
    bucket_id = file_id[3:27]

    info = StoredAccountInfo()

    url = url_for_api(info, 'b2_download_file_by_id')

    print '%s?fileId=%s' % (url, file_id)

def print_ls_entry(is_long, is_folder, name, file):
    # if not long, it's easy
    if not is_long:
        print name
    else:
        # order is file_id, action, date, time, size, name
        format = '%83s  %6s  %10s  %8s  %9d  %s'
        if is_folder:
            print format % ('-', '-', '-', '-', 0, name)
        else:
            file_id = file['fileId']
            action = file['action']
            dt = datetime.datetime.utcfromtimestamp(file['uploadTimestamp'] / 1000)
            date_str = dt.strftime('%Y-%m-%d')
            time_str = dt.strftime('%H:%M:%S')
            size = file['size']
            print format % (file_id, action, date_str, time_str, size, name)

def ls(args):
    # Parse arguments
    long_format = False
    show_versions = False
    while len(args) != 0 and args[0][0] == '-':
        option = args[0]
        args = args[1:]
        if option == '--long':
            long_format = True
        elif option == '--versions':
            show_versions = True
        else:
            print 'Unknown option:', option
            usage_and_exit()
    if len(args) < 1 or 2 < len(args):
        usage_and_exit()
    bucket_name = args[0]
    if len(args) == 1:
        prefix = ""
    else:
        prefix = args[1]
        if not prefix.endswith('/'):
            prefix += '/'

    # Get authorization
    info = StoredAccountInfo()
    bucket_id = get_bucket_id_from_bucket_name(info, bucket_name)
    auth_token = info.get_account_auth_token()

    # Loop until all files in the named directory have been listed.
    # The starting point of the first list_file_names request is the
    # prefix we're looking for.  The prefix ends with '/', which is
    # now allowed for file names, so no file name will match exactly,
    # but the first one after that point is the first file in that
    # "folder".   If the first search doesn't produce enough results,
    # then we keep callig list_file_names until we get all of the
    # names in this "folder".
    current_dir = None
    if show_versions:
        api_name = 'b2_list_file_versions'
    else:
        api_name = 'b2_list_file_names'
    start_file_name = prefix
    start_file_id = None
    while True:
        url = url_for_api(info, api_name)
        params = {
            'bucketId' : bucket_id,
            'startFileName' : start_file_name
            }
        if start_file_id is not None:
            params['startFileId'] = start_file_id
        response = post_json(url, params, auth_token)
        for file in response['files']:
            name = file['fileName']
            if not name.startswith(prefix):
                # We're past the files we care about
                return
            after_prefix = name[len(prefix):]
            if '/' not in after_prefix:
                # This is not a folder, so we'll print it out and
                # continue on.
                file_id = file['fileId']
                size = file['size']
                print_ls_entry(long_format, False, name, file)
                current_dir = None
            else:
                # This is a folder.  If it's different than the folder
                # we're already in, then we can print it.  This check
                # is needed, because all of the files in the folder
                # will be in the list.
                folder_with_slash = after_prefix.split('/')[0] + '/'
                if folder_with_slash != current_dir:
                    folder_name = prefix + folder_with_slash
                    print_ls_entry(long_format, True, folder_name, file)
                    current_dir = folder_with_slash
        if response['nextFileName'] is None:
            # The response says there are no more files in the bucket,
            # so we can stop.
            return

        # Now we need to set up the next search.  The response from
        # B2 has the starting point to continue with the next file,
        # but if we're in the middle of a "folder", we can skip ahead
        # to the end of the folder.  The character after '/' is '0',
        # so we'll replace the '/' with a '0' and start there.
        if current_dir is None:
            start_file_name = response.get('nextFileName')
            start_file_id = response.get('nextFileId')
        else:
            start_file_name = max(
                response['nextFileName'],
                prefix + current_dir[:-1] + '0'
                )


def main():
    if len(sys.argv) < 2:
        usage_and_exit()

    decoded_argv = decode_sys_argv()

    action = decoded_argv[1]
    args = decoded_argv[2:]

    if action == 'authorize_account':
        authorize_account(args)
    elif action == 'clear_account':
        clear_account(args)
    elif action == 'create_bucket':
        create_bucket(args)
    elif action == 'delete_bucket':
        delete_bucket(args)
    elif action == 'delete_file_version':
        delete_file_version(args)
    elif action == 'download_file_by_id':
        download_file_by_id(args)
    elif action == 'download_file_by_name':
        download_file_by_name(args)
    elif action == 'get_file_info':
        get_file_info(args)
    elif action == 'hide_file':
        hide_file(args)
    elif action == 'list_buckets':
        list_buckets(args)
    elif action == 'list_file_names':
        list_file_names(args)
    elif action == 'list_file_versions':
        list_file_versions(args)
    elif action == 'ls':
        ls(args)
    elif action == 'make_url':
        make_url(args)
    elif action == 'update_bucket':
        update_bucket(args)
    elif action == 'upload_file':
        upload_file(args)
    elif action == 'version':
        print 'b2 command line tool, version', VERSION
    else:
        usage_and_exit()

if __name__ == '__main__':
    main()
